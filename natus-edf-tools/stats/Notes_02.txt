Presentation Anouncement text (not changable for your information)
In this session, I (Milad Khaki, Biomedical Data Scientist) will present recent infrastructure advancements that reinforce the research backbone of LHSC‚Äôs Epilepsy Monitoring Unit. My work addresses critical challenges in managing large-scale SEEG datasets, including anonymization, standardization, compatibility, and long-term data stewardship.
These engineering contributions enable:
Scalable and compliant data pipelines that support ethical research on sensitive patient recordings
Automated and reproducible workflows that reduce manual burden and promote consistency across studies
Interoperability with community-standard tools, making it easier to share, compare, and extend SEEG datasets.
Optimized storage and archival strategies that improve capacity and ensure long-term reliability
I will also reflect on a core principle: Invisible infrastructure signals optimal design. 
The aim is for clinicians and researchers to interact with data effortlessly ‚Äî without disruptions, hidden privacy risks, or technical detours. These invisible systems are what quietly sustain robust and scalable neuroscience research.
Best regards,
Milad Khaki, Ph.D.
SEEGWay Journal Club Coordinator


Presentation materials:

SLide1:
Advancing EMU Storage and SEEG Data Pipelines

slide 2:
Outline:
Goal: Build invisible, robust infrastructure for SEEG research
Context: Large-scale, sensitive SEEG datasets from the EMU
Challenge: Ensure reliability, privacy, and interoperability
Key Idea: When it works, you shouldn't notice it

Slide 3:
Design Philosophy: ‚ÄúReliable infrastructure should feel invisible ‚Äî not absent.‚Äù


Great systems feel invisible ‚Äî nothing disrupts your flow

When something breaks, it's fixed before you notice

Behind the scenes, resilient engineering powers seamless neuroscience research


Slide 4: (talking about my previous experiences and why I am a good choice for this task)

Previous Big Data Experiences
üü¶ Urban Water Consumption (Abbotsford, BC)
Hourly usage data from 25,000 households
Processed over 1 billion rows covering multiple years
Used for peak demand analysis and infrastructure planning

üü© Municipal Infrastructure Project
Historical tender data for Waterloo, London, Niagara Falls (1980‚Äìpresent)
Structured and indexed ~5,000 project records
Applied NLP models to extract unit cost, scope, and type from free text

üü® Livestock Monitoring (Ontario)
Biological telemetry for over 2,000 cattle, sampled every 15 minutes
Multi-sensor data: water intake, body temp, feeding behaviour
Used for anomaly detection and health pattern modelling


Slide 5:
From Large-Scale Data to EMU-Specific Challenges

Leveraging experience with multi-million-row datasets, the EMU brings new challenges 
unique to clinical neuroscience:

ÔÅÆ 	Massive daily throughput:	Clinical recordings generate up to 100 GB per patient per day.

ÔÅÆ 	Privacy-sensitive data:	Manual/Semi-automated anonymization introduces risk and inconsistency.

ÔÅÆ 	Incompatible exports:	Vendor-specific formats hinder analysis and reproducibility.

ÔÅÆ 	Storage strain:	Redundancy, retention, and space planning require active engineering


Slide 6:
System Architecture

Pipeline stages: Ingest ‚Üí Anonymize ‚Üí Export ‚Üí Archive
Focus: Research workflow (not direct clinical use)
Goals: Modularity, reproducibility, automation


Slide 7:
SEEG Data Pipeline Overview

üîµ Step A: Natus Data Export (Manual + Semi-Automated)
üü° Step B: BIDS Conversion and Redaction
üü£ Step C: Redaction Check
üü¢ Step D: Archival & Compression
üîµ Step E: Provenance, Logging, and Cleanup

Slide 8:
SEEG Pipeline diagram

Slide 9:
What was available when I joined EMU

Slide 10:
	A. Natus Data Export
	Goal: Extract patient EEG sessions from the Natus system and prepare them for research processing.

	üõ† Tools & Tasks:
	NatusExportList_Generator.py
	Generates batch export lists for EDF export from .eeg folders, using a constant export configuration path.

	Natus_InfoExtractor_v2.py
	Extracts structured metadata (e.g., recording start time, classification, duration) from .eeg/.ent files.

	Natus_InfoServerScraper.py
	Audits folders to confirm the presence and correctness of exported .eeg files against expected patterns.

	Manual/Tech Tasks:

	Run Natus Neuroworks export tool

	Identify and flag sessions of interest (STIM / LFSTIM / ABLATION)

	Initial verification of EDF header integrity


Slide 11:
	üÖ± B. BIDS Conversion & Redaction
	Goal: Convert raw EEG sessions to BIDS-compliant format and ensure initial anonymization.

	üõ† Tools & Tasks:
	data2bids (by Dr. Greydon Gilmore)
	Converts Natus output into BIDS-compliant folder structure (including iEEG modality and metadata files).

	redactor_TSV_JSON.py
	Redacts names from .tsv and .json files using a fast Aho‚ÄìCorasick matching algorithm and demographic name lists.

	EDF_Handler.py (GUI)
	A graphical launcher for all processing tools with dynamic argument selection and execution preview.

	Manual patching & QA:

	Detect previously missed PHI in event annotations

	Correct exported metadata as needed


Slide 12:
	üÖ≤ C. Redaction Check
	Goal: Ensure all patient identifiers are removed from both EDF files and accompanying metadata.

	üõ† Tools & Tasks:
	EDF_Anonymization_Scanner.py
	Scans EDF headers and annotation channels for names, IDs, emails, and other identifiers. Logs and outputs detected matches.

	redactor_EDF_EmbeddedAnnotations.py
	Applies robust redaction to EDF headers and embedded TALs using memory-mapped processing and pattern matching.

	EDF_Compatibility_Check_Tool.py
	Verifies whether modified EDF files remain loadable in standard clinical software (e.g., EDFBrowser).

	EDF_time_calculator.py
	Computes EDF clipping ranges for analysis or anonymization using exact timestamps and durations.


Slide 13:
	üÖ≥ D. Archival & Compression
	Goal: Reduce storage demands by compressing validated EDF files while preserving retrievability and traceability.

	üõ† Tools & Tasks:
	search_validate_update_of__compressed_folders.py
	Full pipeline for:

	Extracting EDFs from .rar

	Redacting

	Repacking

	Verifying via MD5

	Logging and flagging any mismatches

	EDF_RAR_archive_purger.py
	Deletes raw .edf files only after .rar, .equal, and .md5 checks pass.

	search_and_validate_compressed_folders.py
	Daemon-like monitor that checks .rar+.edf combinations and validates archives continuously.

Slide 14:
	üÖ¥ E. Provenance & Cleanup
	Goal: Finalize archival integrity, ensure reproducibility, and clean temporary data artifacts.

	üõ† Tools & Tasks:
	Server_update_check.py
	Compares mirrored storage trees (e.g., Nebula vs local copy) to detect missing or outdated files.

	Natus_Log_Parser.py
	Extracts anonymization mappings from redaction log files for audit trail reconstruction.

	Tool-integrated logging and CSV/JSON export:

	Each tool generates logs for redaction, MD5 comparison, and export decisions

	Cleaned EDFs and compressed artifacts are moved into structured provenance directories


Slide 15:
	EDFbrowser, A Cornerstone for SEEG Data Inspection and Validation


	What is EDFbrowser?
Free, open-source, EDF+ viewer editor
Why It Matters
Implemented in C++ (high performance)
Visual inspection tool


Slide 16:
	image (edf browser), showing how we can load two edf files togehter and double check that data export is done correctly, sync is correct, etc.
	
	
Slide 17: 
	showing splash screens for edf browser and the new edfbrowser BIDS (customized version done by me)
	
	talking about that I have changed the source code and recompiled it with command line tools to be used in the pipeline.
	
Slide 18: 
	demonstration of how my changes allows for EDF compatibility check:
	
	c:\edfbrowser.exe --check-compatibility e:\sub-030_ses-027_task-full_run-01_ieeg.edf
	Found the argument, Opening input file: e:\sub-030_ses-027_task-full_run-01_ieeg.edf
	Starting EDF compatibility check for: e:\sub-030_ses-027_task-full_run-01_ieeg.edf
	EDF Header loaded correctly

	Checking datarecord 1/2809475 (0%)..... (100%)

	== Data Validation == Checking all samples against digital min/max values...
	Signal 251: C250            , 64 samples/record, min: -32768, max: 32767
	Signal 258: DC1             , 64 samples/record, min: -32768, max: 32767
	Signal 274: TRIG            , 64 samples/record, min: -32768, max: 32767
	Signal 278: EDF Annotations , 144 samples/record, min: -32768, max: 32767

	== Errors Compatibility check passed: File is a valid EDF+ file.
	Number of signals: 278
	Data record duration: 0.031250
	Recording length in Sec: 78998437500
	Number of data records: 2809475
	Discontinuous state of file: <0>
	Recording duration: 7899 seconds
	Result saved to: ‚Äúe:/ sub-030_ses-027_task-full_run-01_ieeg.edf_pass"
	Check completed!

Slide 19:
	image (reduce signals and/or duration menu of EDF browser that has additional buttons done by me to load required configuration from a json file)

Slide 20:
	images: demo
	
	image 1: Sample EDF header info with start time/date, duration and number of data records
	image 2: showing how MK_EDF_Handler and specifically, EDF_Time_Calculator can use these information with the additional start and end time that we want to clip and the pre / post buffers to generate the record numbers to input into the reduce signal tool.

Slide 21:
	image 1: reminder of image 2 in slide 20, 
	image 2: what will change in the reduce signals menu to select the exact time and signals we want.
	
Slide 22:
	images
	
	image 1: reminder of the image 2 on slide 20, 
	
	image 2: EDF info of the output file showing the exact times for start / end / duration / and signals of the output resulting file
	
Slide 23:

	example of tampering with a 6GB edf file and writing 40KB random data into it to test compatibility checker
	
	image 2: showing the diagram of two massive edf files compared (like bad sector diagram) showing it is possible to detect this miniscule error in this massive file when compared to the original.
	
Slide 24: 
	Output of the edf compatibility checker:
	
	Timestamp: 2025-04-24 14:42:51
	File: e:\sub-167_ses-007_task-full_run-01_ieeg_reduced.edf

	Output:
	Opening input file: e:\sub-167_ses-007_task-full_run-01_ieeg_reduced.edf
	Starting EDF compatibility check for: e:\sub-167_ses-007_task-full_run-01_ieeg_reduced.edf
	EDF Header loaded correctly
	== Statistics ==
	Total samples checked: 2930144745
	Samples out of range: 12
	Sample errors detected: 12
	Annotation errors detected: 5
	Timing errors detected: 1
	Total error count: 18
	== Result ==
	Compatibility check FAILED. File does not comply with the EDF+ specification.
	See detailed errors above for specific issues.
	Compatibility check failed: File is NOT a valid EDF or BDF file.
	Error: ERROR 2: Datarecord 207939, signal 218, sample 10 below digital minimum. Value: -11648, Min: 0, Offset: 0x5D386AB2
	ERROR 3: Datarecord 207939, signal 218, sample 11 below digital minimum. Value: -13202, Min: 0, Offset: 0x5D386AB4
	ERROR 4: Datarecord 207939, signal 218, sample 17 below digital minimum. Value: -24857, Min: 0, Offset: 0x5D386AC0
	ERROR 5: Datarecord 207939, signal 218, sample 18 below digital minimum. Value: -15410, Min: 0, Offset: 0x5D386AC2
	ERROR 6: Datarecord 207939, signal 218, sample 19 below digital minimum. Value: -8756, Min: 0, Offset: 0x5D386AC4
	ERROR 7: Datarecord 207939, signal 218, sample 20 below digital minimum. Value: -4004, Min: 0, Offset: 0x5D386AC6
	ERROR 8: Datarecord 207939, signal 218, sample 21 below digital minimum. Value: -20024, Min: 0, Offset: 0x5D386AC8
	ERROR 9: Datarecord 207939, signal 218, sample 22 below digital minimum. Value: -14681, Min: 0, Offset: 0x5D386ACA
	ERROR 10: Datarecord 207939, signal 218, sample 23 below digital minimum. Value: -22592, Min: 0, Offset: 0x5D386ACC
	Note: Additional sample range errors may exist but won't be individually listed.
	ERROR 11: Invalid annotation in datarecord 207939, last byte is not a null-byte. Offset: 0x5D386C2F
	ERROR 12: Invalid annotation in datarecord 207939, could not find timekeeping annotation. This is required for EDF+/BDF+ files. Offset: 0x5D386C20
	ERROR 13: Datarecord 207940, signal 1, sample 1 exceeds digital maximum. Value: 29320, Max: 1, Offset: 0x5D386C30
	Note: Additional sample range errors may exist but won't be individually listed.
	ERROR 14: Invalid annotation in datarecord 207940, last byte is not a null-byte. Offset: 0x5D38DA3F
	ERROR 15: Invalid annotation in datarecord 207940, could not find timekeeping annotation. This is required for EDF+/BDF+ files. Offset: 0x5D38DA30
	ERROR 16: Invalid annotation in datarecord 207940, byte before the first null-byte should be 0x14. Offset: 0x5D38DA3B
	ERROR 17: Datarecord 207941, signal 1, sample 1 exceeds digital maximum. Value: 27775, Max: 1, Offset: 0x5D38DA40
	Note: Additional sample range errors may exist but won't be individually listed.
	ERROR 18: Datarecord duration is 0.031250000000 but timestep between datarecord 207941 and preceding datarecord is 0.093750000000. Offset: 0x5D394840

	Elapsed Time: 18.28 seconds

	also mentioning that although it was possible to detect this error, if the error is small enough we cannot detect it. So we need to use the checksum method for chunks of EDF file and generate a checksum table for parts of the file to check if it is intact in the future.
	
Slide 25:
	Key Engineering Contributions
	

	Automated anonymization (headers + embedded annotations)
	Validation tools to ensure EDF compatibility (EDFBrowser)
	Session parsing, silent failure detection, and clipping tools
	GUI-based management of pipeline steps for usability
	Redundant archival and optimized compression 

Slide 26:
	Impact and Future Vision
	
	Secure, scalable, reproducible data workflows
	Foundation for multi-project collaboration
	Positioned for future automation and AI integration


Slide 27:
	Thank you.





























































































































































































